{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to `eudsl-python-extras` enjoy your stay!\n",
    "\n",
    "more at https://github.com/llvm/eudsl/tree/main/projects/eudsl-python-extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install eudsl-python-extras mlir-python-bindings -f https://llvm.github.io/eudsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import mlir.extras.types as T\n",
    "from mlir.dialects import builtin\n",
    "from mlir.dialects.transform import any_op_t\n",
    "from mlir.dialects.transform.extras import named_sequence, apply_patterns\n",
    "from mlir.extras.util import find_ops\n",
    "from mlir.ir import StringAttr, UnitAttr\n",
    "\n",
    "# you need this to register the memref value caster\n",
    "# noinspection PyUnresolvedReferences\n",
    "import mlir.extras.dialects.memref\n",
    "from mlir.extras.context import RAIIMLIRContext, ExplicitlyManagedModule\n",
    "from mlir.dialects.bufferization import LayoutMapOption\n",
    "from mlir.dialects.transform.vector import (\n",
    "    VectorContractLowering,\n",
    "    VectorMultiReductionLowering,\n",
    "    VectorTransferSplit,\n",
    "    VectorTransposeLowering,\n",
    ")\n",
    "from mlir.extras.dialects import linalg\n",
    "from mlir.extras.dialects.func import func\n",
    "from mlir.extras.dialects.transform import (\n",
    "    match,\n",
    "    tile_to_scf_for,\n",
    "    get_parent_op,\n",
    "    transform_any_op_t,\n",
    ")\n",
    "from mlir.extras.dialects import transform\n",
    "from mlir.extras.runtime.passes import Pipeline, run_pipeline\n",
    "from mlir.extras.runtime.refbackend import LLVMJITBackend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-JTcrjo7tNK"
   },
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGpWj9BzZLC_"
   },
   "outputs": [],
   "source": [
    "ctx = RAIIMLIRContext()\n",
    "module = ExplicitlyManagedModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGcDtgkv71YB"
   },
   "source": [
    "# Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oQk4xJd72FI"
   },
   "outputs": [],
   "source": [
    "M, K, N = 2, 4, 6\n",
    "\n",
    "\n",
    "@func\n",
    "def matmul_tensors(\n",
    "    A: T.tensor(M, K, T.f32()),\n",
    "    B: T.tensor(K, N, T.f32()),\n",
    "    C: T.tensor(M, N, T.f32()),\n",
    "):\n",
    "    return linalg.matmul(A, B, C)\n",
    "\n",
    "@builtin.module(attrs={\"transform.target_tag\": StringAttr.get(\"payload\")})\n",
    "def payload():\n",
    "    matmul_tensors.emit(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0vJZrpR74KB"
   },
   "source": [
    "# Transform schedule (based on [transform-e2e.mlir](https://github.com/llvm/llvm-project/blob/375bd2201ce0d2c76cb47a02c87b8ca5ba8a3509/mlir/test/Dialect/LLVM/transform-e2e.mlir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaBgGTIz72ci"
   },
   "outputs": [],
   "source": [
    "@builtin.module(attrs={\"transform.with_named_sequence\": UnitAttr.get()})\n",
    "def mod_transform():\n",
    "    @named_sequence(\"main\", [any_op_t()], [])\n",
    "    def main(module_op: any_op_t()):\n",
    "        matmul = match(module_op, ops=[\"linalg.matmul\"])\n",
    "        tiled_matmul, (_, _, inner_loop) = tile_to_scf_for(matmul, sizes=[2, 2, 2])\n",
    "        transform.structured.vectorize_children_and_apply_patterns(\n",
    "            get_parent_op(transform_any_op_t(), tiled_matmul, isolated_from_above=True)\n",
    "        )\n",
    "        new_mod = transform.bufferization.one_shot_bufferize(\n",
    "            module_op,\n",
    "            function_boundary_type_conversion=LayoutMapOption.IdentityLayoutMap,\n",
    "            bufferize_function_boundaries=True,\n",
    "        )\n",
    "\n",
    "        func_op = match(new_mod, ops=[\"func.func\"])\n",
    "\n",
    "        @apply_patterns(func_op)\n",
    "        def pats():\n",
    "            transform.apply_patterns.vector.lower_contraction(\n",
    "                lowering_strategy=VectorContractLowering.OuterProduct\n",
    "            )\n",
    "            transform.apply_patterns.vector.transfer_permutation_patterns()\n",
    "            transform.apply_patterns.vector.reorder_and_expand_multi_reduction_dims(\n",
    "                lowering_strategy=VectorMultiReductionLowering.InnerParallel\n",
    "            )\n",
    "            transform.apply_patterns.vector.multi_reduction_flattening(\n",
    "                lowering_strategy=VectorMultiReductionLowering.InnerParallel\n",
    "            )\n",
    "            transform.apply_patterns.vector.multi_reduction_unrolling(\n",
    "                lowering_strategy=VectorMultiReductionLowering.InnerParallel\n",
    "            )\n",
    "            transform.apply_patterns.vector.split_transfer_full_partial(\n",
    "                split_transfer_strategy=VectorTransferSplit.LinalgCopy\n",
    "            )\n",
    "            transform.apply_patterns.vector.transfer_to_scf(\n",
    "                max_transfer_rank=1, full_unroll=True\n",
    "            )\n",
    "            transform.apply_patterns.vector.lower_transfer(max_transfer_rank=1)\n",
    "            transform.apply_patterns.vector.lower_shape_cast()\n",
    "            transform.apply_patterns.vector.lower_transpose(\n",
    "                lowering_strategy=VectorTransposeLowering.Shuffle1D\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADbabroS8ND2"
   },
   "source": [
    "# \"Finish\" the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUOsYXaW8QKC",
    "outputId": "f8592229-1d9b-4c52-9133-30fd52c2716d"
   },
   "outputs": [],
   "source": [
    "module = module.finish()\n",
    "print(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xN5kNvZ8Tyf"
   },
   "source": [
    "# Vectorize (execute the transform schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLwQLPD98Q4d",
    "outputId": "ecfa6c9a-15eb-40c7-df29-f43fcac02fbf"
   },
   "outputs": [],
   "source": [
    "vectorized_module = run_pipeline(\n",
    "    module,\n",
    "    pipeline=Pipeline().transform_interpreter(\n",
    "        entry_point=\"main\", debug_payload_root_tag=\"payload\"\n",
    "    ),\n",
    ")\n",
    "print(vectorized_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_NURglF8ZZW"
   },
   "source": [
    "# Lower to CPU (through LLVM, based on [TestLowerToLLVM.cpp](https://github.com/makslevental/llvm-project/blob/f6643263631bcb0d191ef923963ac1a5ca9ac5fd/mlir/test/lib/Dialect/LLVM/TestLowerToLLVM.cpp#L44))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IoWjgc48bcn",
    "outputId": "39550464-fd37-4e6d-a257-e803b746d8de"
   },
   "outputs": [],
   "source": [
    "lower_to_llvm = (\n",
    "    Pipeline()\n",
    "    .Func(\n",
    "        Pipeline()\n",
    "        # Blanket-convert any remaining high-level vector ops to loops if any remain.\n",
    "        .convert_vector_to_scf()\n",
    "        # Blanket-convert any remaining linalg ops to loops if any remain.\n",
    "        .convert_linalg_to_loops()\n",
    "    )\n",
    "    # Blanket-convert any remaining affine ops if any remain.\n",
    "    .lower_affine()\n",
    "    # Convert SCF to CF (always needed).\n",
    "    .convert_scf_to_cf()\n",
    "    # Sprinkle some cleanups.\n",
    "    .canonicalize()\n",
    "    .cse()\n",
    "    # Convert vector to LLVM (always needed).\n",
    "    .convert_vector_to_llvm()\n",
    "    # Convert Math to LLVM (always needed).\n",
    "    .Func(Pipeline().convert_math_to_llvm())\n",
    "    # Expand complicated MemRef operations before lowering them.\n",
    "    .expand_strided_metadata()\n",
    "    # The expansion may create affine expressions. Get rid of them.\n",
    "    .lower_affine()\n",
    "    # Convert MemRef to LLVM (always needed).\n",
    "    .finalize_memref_to_llvm()\n",
    "    # Convert Func to LLVM (always needed).\n",
    "    .convert_func_to_llvm()\n",
    "    .convert_arith_to_llvm()\n",
    "    .convert_cf_to_llvm()\n",
    "    # Convert Index to LLVM (always needed).\n",
    "    .convert_index_to_llvm()\n",
    "    # Convert remaining unrealized_casts (always needed).\n",
    "    .reconcile_unrealized_casts()\n",
    ")\n",
    "\n",
    "backend = LLVMJITBackend()\n",
    "compiled_module = backend.compile(\n",
    "    find_ops(\n",
    "        vectorized_module.operation,\n",
    "        lambda x: \"transform.target_tag\" in x.attributes\n",
    "        and x.attributes[\"transform.target_tag\"].value == \"payload\",\n",
    "        single=True,\n",
    "    ),\n",
    "    kernel_name=matmul_tensors.__name__,\n",
    "    pipeline=lower_to_llvm,\n",
    ")\n",
    "print(compiled_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOapyydH8n4h"
   },
   "source": [
    "# Load, run, and compare against numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOEC4Qgw8p9X"
   },
   "outputs": [],
   "source": [
    "A = np.random.randint(0, 10, (M, K)).astype(np.float32)\n",
    "B = np.random.randint(0, 10, (K, N)).astype(np.float32)\n",
    "C = np.zeros((M, N), dtype=np.float32)\n",
    "\n",
    "backend.load(compiled_module).matmul_tensors_capi_wrapper(A, B, C)\n",
    "assert np.allclose(A @ B, C)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
